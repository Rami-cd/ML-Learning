{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>    Feature scaling part 1\n",
    "\n",
    "</h1>\n",
    "\n",
    "<style>\n",
    "    h1{\n",
    "        color: lightseagreen;\n",
    "        width: 100%;\n",
    "        text-align: center;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature scaling part 1</h2>\n",
    "\n",
    "<img src=\"images/69.png\">\n",
    "\n",
    "here the house size take a large range of values, and the number of bedrooms have a small range of values.\n",
    "\n",
    "given some training examples.\n",
    "\n",
    "we take 2 values for $w_{1}$ and $w_{2}$ where $w_{1}$ is large and $w_{2}$ is small then we repeat it the other way arround.\n",
    "\n",
    "the second version have much better prediction.\n",
    "\n",
    "So when a possible major features is large, like the $feet^{2}$ a good model will learn to choose the relatively parameter value like the `0.1`, when the possible values of the features are small then the reasonable value of this parameter is relatively large, the `50`.\n",
    "\n",
    "<img src=\"images/70.png\">\n",
    "\n",
    "in the ***scatterplot*** the horizontal change on the x-axis have a wider range than the y-axis.\n",
    "\n",
    "for the ***contour plot*** the vertical axis take a much larger value than the horizontal axis, the contour from ellipses longer on 1 side shorter on the other.\n",
    "\n",
    "a small change on $w_{1}$ can have a very large inpact on the estimated price, hence a very large inpact on the cost `J` because $w_{1}$ is mutplied by a very large number, in contrast it take much larger change to $w_{2}$ to change the prediction much.\n",
    "\n",
    "<img src=\"images/71.png\">\n",
    "\n",
    "since the contours are so tall and thin the gradient dscent might end up bouncing back and forth for so long before it can find the global minimum.*(in red)*\n",
    "\n",
    "a useful thing to do is to scale the transformations, here we made $x_{2}$ smaller, so now $x_{1}$ and $x_{2}$ are taking comparable variables, now the contours are circles the gradient descent can have much more direct path to global minimum.\n",
    "\n",
    "<h2>Feature scaling part 2</h2>\n",
    "\n",
    "<img src=\"images/72.png\">\n",
    "\n",
    "we divide both the scales with the max so the range now is `1 < r < 0`, now if we plot it on the graph it's better.\n",
    "\n",
    "<img src=\"images/73.png\">\n",
    "\n",
    "***Mean normalization*** we center them so they both are around 0, between 1 and -1.\n",
    "\n",
    "<img src=\"images/74.png\">\n",
    "\n",
    "***Z-score mormalization*** it uses standard deviation.\n",
    "\n",
    "<img src=\"images/75.png\">\n",
    "\n",
    "we aim to a rescaling close to -1 < r < 1\n",
    "\n",
    "<h2>Checking gradient descent for convergence</h2>\n",
    "\n",
    "to make sure gradient descent is working well.\n",
    "\n",
    "<img src=\"images/76.png\">\n",
    "\n",
    "the horizontal axis is the number of iterations.\n",
    "\n",
    "<p style=\"color: crimson\">if J increase after and iteration, that means either α is choosen poorly (usually α is to large).<br>\n",
    "or could be a bug in the code</p>\n",
    "\n",
    "by 400 iterations the curve have flatten out, so the cost function converge.\n",
    "\n",
    "the number of iterations differ for each model, it's hard to know the number of iterations.\n",
    "\n",
    "Another way to descide when the model is done training is ***Automatic convergence test***:\n",
    "\n",
    "if `J` decreases for less than epsilon on 1 iteration.\n",
    "\n",
    "\n",
    "\n",
    "<style>\n",
    "    img {\n",
    "        width: 500px;\n",
    "        height: 340px;\n",
    "        border: 1px solid lightseagreen;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    h2 {\n",
    "        margin-left: 20px;\n",
    "        color: lightseagreen;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Choosing the learning rate</h2>\n",
    "\n",
    "in the first graph the gradient descent is not working properly, in the second graph if `α` is too big the cost will go up.\n",
    "\n",
    "or it can be a bug if `J` increases even with small `α`.\n",
    "\n",
    "<img src=\"images/78.png\">\n",
    "\n",
    "\n",
    "<style>\n",
    "    img {\n",
    "        width: 500px;\n",
    "        height: 340px;\n",
    "        border: 1px solid lightseagreen;\n",
    "        border-radius: 10px;\n",
    "    }\n",
    "    h2 {\n",
    "        margin-left: 20px;\n",
    "        color: lightseagreen;\n",
    "    }\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
